### Logical/Physical Topology-Aware Collective Communication

![image-20240724172304715](C:\Users\tbj20\AppData\Roaming\Typora\typora-user-images\image-20240724172304715.png)

a. 传统场景，无重叠；

b. 为减小通信时间，将通信延时隐藏在反向计算梯度聚合中；

c.  本文的做法，将通信延时隐藏在下一次正向传输中。和b相比，开始通信的时间被推迟了，然而，由于数据依赖性，在第一层的通信需求完成前，下一次的前向传播不会开始，C1这一通信延迟不会被重叠。c可以让非重叠时间保持最小，但是b不一定。例如，如果通信时间更长，C1可能不能在B1后马上开始，然而c可以防止这种情况的出现。

在前向计算重叠可以使得传输是按序的，可以使用“one-shot”集合通信，也就是说在结束后向传播后只做一次集合通信，而b的方案需要做4次通信。以前的工作提出通过在异步平行训练使用参数服务器，“layer-wise”（粗粒度）或分片（细粒度）方案隐藏通信开销。Layer-wise方案在梯度从各层反向计算后产生时通信；slicing方案将通信分为更小的粒度，以更好的隐藏参数服务器的参数更新。细粒度通信可以提高参数服务器与工作节点之间的整体性能，但是切分数据（导致增加集体通信的次数）会增加性能开销，并降低集体通信的性能。据图可知，Layer-wise或分片操作需要调用多次Allreduce，性能比one shot分别差了两倍和四倍。本文不会再将数据分成任何细粒度，而是利用通信中的最佳块大小，在GPU之间进行数据通信的流水线化处理。

为了理解以树为基础的AllReduce算法，我们使用了一个线性通信开销模型：$\alpha+\beta N$

$\alpha$：设备间延迟部分；$\beta$：带宽部分（=$\dfrac{1}{bandwidth}$）；N：信息大小

也就是延迟+通信时间

AllReduce的环算法包含两步，分别是Reduce-Scatter和AllGather，在每个阶段内进行的通信是相同的。信息量 N 被分成了 P大份,P为处理节点的数目，每份大小为$\dfrac{N}{P}$，每份数据都会经过除了自己的每个节点，总共需要 P - 1 步。AllGather也可以用公式概括：$T_{AllGather} = (P-1)(\alpha + \beta \dfrac{N}{P})$，那么环AllReduce算法使用了两次 AllReduce的时间，即$T_{ring} = 2(P-1)(\alpha+\beta\dfrac{N}{P})$；

AllReduce的树算法将Reduction和Broadcast结合起来，但是通信步骤的数目变成了$\log(P) + K$。其中 P 是指处理器的数目，K 是数据份数。树算法的每一个阶段的表现为：$T_{reduction}=T_{broadcast}=(\log(P) + K)(\alpha + \beta \dfrac{N}{K})$

环和树算法的不同：

随着数据量的减小，树环比增大；随着节点数目的增加，树环比增大，这就是因为树算法的可扩展性优于环算法。

观察结论1：

由于树算法的流水特性，一些数据块完成 reduce，等待其他数据块被 reduce 在 broadcast 操作之前；

观察结论2：

树算法中物理拓扑连接双向，包含两个方向，下行物理连接在 reduce 时用不到，同理，上行连接在 broadcast 用不到。

双二叉树算法（NCCL2.4）可以完全使用上下行带宽，但是如果这样的话，通信时间的重叠就无法进行，因为一些物理链路在另一棵树上被利用了----这在光网络中不是问题。

观察结论3：

数据的 reduce 和 broadcast 操作是按序的

观察结论4：

物理拓扑可以提供额外的连接，在C-cube中可以利用，利用多余的连接可以做到在双二叉树算法下重叠通信时间。

重叠双二叉树算法可以使用更短的步骤完成集合通信。

不仅是通信时间自己可以重叠，通信时间还可以和计算时间重叠

重叠思路：在第一个数据块完成后使用梯度队列重叠通信和计算，而不是等待整个通信结束。等待上一层计算完，找队列第一个代表的层，对继续计算该层，这个过程通信也在进行计算。

![](C:\Users\tbj20\AppData\Roaming\marktext\images\2024-07-30-21-16-56-image.png)

物理拓扑感知：------光网络中没有此问题

依靠绕行来增加可利用链路
