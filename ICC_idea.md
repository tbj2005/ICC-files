#### 面向混合并行分布式机器学习的业务部署和集合通信方案选择

##### 一. 并行方案

数据并行（DP）、流水线并行（PP）、张量并行（TP）、专家并行（EP）等

通信量：TP >> DP > PP，EP的通信量在看到的文献中没有提及

涉及的通信流量：

DP：AllReduce

PP：Send-Recv

TP：AllReduce

EP：AlltoAll

其中 TP 通信量非常大，通常使用服务器内部 GPU 间的 NVLink 高速通信，而不涉及跨服务器带宽，在场景中可以不再考虑，部署也是以服务器为最小单位。

##### 二. AllReduce 通信算法

###### 1. Parameter-server：

确定拓扑方便（只需确定数据并行单元部署位置即可），使用限制多（单 pod、ToR 上的 INC 资源）。在使用 INC 后，通信时间是所有方案中最小的，而且不会使用 OXC 资源；但是如果没有使用 INC，通信时间和带宽使用就是所有方案中最多的。

###### 2. ring-Allreduce:

单节点接受发送数据量达到最小，输入输出带宽用满，但是如果不只考虑带宽，再考虑每次传输的延迟

使用线性通信开销模型,$T = \alpha+S/B$

$T = （N - 1）(2\alpha + 2\dfrac{S}{NB}+\dfrac{SC}{N})$

其中， $\alpha$为设备间的通信固有延时，S为数据块大小，N 为节点数目，B为节点带宽，C为每字节计算耗时。

当 S 极大时，固有延时 $\alpha$ 可以忽略，此时随着N 的增大，延时 T 与 N 无关，为$T = 2\dfrac{S}{B}+SC$。

但是当 S 特别小，或者 N 特别大时，后两项就被忽略了，此时 $T = 2(N-1)\alpha$，此时延时由固有延时决定，随着 N 的增大持续增加。这也是环算法的缺陷，正因如此，树算法才被开发出来。

###### 3. tree-AllReduce:

树算法实际在英伟达 NCCL 投入使用的方案是双二叉树法，使用两个对称二叉树解决传统单二叉树算法节点输入输出带宽量不同的问题。

根据论文，其延迟为$T \leq 4\alpha\log N+\dfrac{2S}{B}+2\sqrt{8\log N\alpha\dfrac{S}{B}}+(\sqrt{2\log N\alpha S}+S)C$

可以看出树算法对 N 极大的情况表现比环算法好得多。

但是树算法在同样的节点数目情况下，需要建立的连接数比环算法多得多，拓扑的复杂度更高。

###### 4. 分层ring-AllReduce:

即将环分为两层，可以缓解 N 极大带来的延迟提高。连接数多于普通环算法，但是总时间在 N 较大时更低。但是如果 N 非常大，树算法的表现更好。

后三种算法拓扑的灵活度非常高，不仅要确定服务器的部署，还要需要确定怎样组成环/树，这也是算法需要考虑的部分。

##### 三. 网络架构

脊叶架构，分为三层：

底层为服务器资源池，由若干服务器组成，每个服务器内部有有限数目的 GPU ，使用张量并行；

中层为 ToR 层，相当于叶交换机，每个 ToR 和其连接的所有服务器组成一个 pod，每个服务器都有一张 NIC 与 ToR 交换机相连；

顶层为 OXC 层，相当于脊交换机，一个 OXC 互联了所有 pod，每个 pod 都分配了若干 OXC 端口，端口之间只能一一互联，可以同时提供双向连接，即全双工。

##### 四. 场景建模

1. 网络中存在若干已知混合并行方案，已知并行度和数据传输总量的业务队列，初始网络中 GPU 和带宽资源使用量为0；

2. 确定业务部署优先级，并确定这些方案在不同集合通信算法下的不同业务部署方案，限制：服务器资源池限制，INC 资源限制、带宽限制、OXC 端口限制还有每次迭代过程不能出现需要进行 OXC 重构的需求，这不仅对减少通信时间有利，还便于分析；

3. 计算不同部署方案此时的收益，以此确定需要使用的集合通信算法和业务部署方案（收益表征：相关 GPU 平均计算时间占比，这个时间越大，所有业务的训练效率越高，此时业务的训练总效率最高，毕竟迭代次数不确定，不好求总运行时间）；

4. 将算法从静态扩展到动态在线场景。

##### 五. 背景增量

1. 考虑混合多种并行方案的业务部署；

2. 考虑多种集合通信算法的选择；
