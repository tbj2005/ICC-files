# 面向混合并行场景下AI流量的光互连数据中心网络调度

## 背景：

在大模型训练过程中，由于数据集合参数规模越来越大，单卡早已无法支持当前业务的训练，因此需要使用并行方案将单卡的训练压力稀释到多卡。AI 大模型训练任务~~~~需要多卡多节点分布式并行完成，集群规模扩展到万卡及以上数量级。当前 GPU 算力快速增长，网络通信正在拖大模型训练的后腿。

- 为了加速网络通信，可以引入光互连数据中心，利用其吞吐量高的优势，为通信提供更高的带宽，以缩短通信时间。然而，当前光互连 DCN 中，POD间的光连接拓扑重构延时高与大模型高效的传输需求并不符合，因此当前的大模型训练没有大规模采用光互连数据中心。在当前，计算和通信具有依赖性，在计算的时候链路往往是闲置的，计算资源和带宽资源总会有一个偷懒，不完全符合当优质帕鲁的要求。但是，由于AI流量具有时序性，可预测性强，可以通过设计面向AI流量的调度算法，将重构延时隐藏在计算过程中，扬长避短，提高训练过程中的网络通信能力。

混合并行是当前大模型训练的热门方案，具体是对同一训练模型采用多种并行方案，即复用分布式数据并行和模型并行，融合两种并行策略的优势以优化训练过程，降低单卡负担。其中，模型并行有多种方案，如流水线并行、张量并行等。

分布式数据并行将数据集均分成数据并行度大小数目的子集，从一轮迭代开始，在每个节点使用不同的子集训练相同大小的模型，然后每个节点再将得到的参数进行聚合和下发，然后开始下一轮的迭代，可以大幅降低节点训练数据量大小。节点间的通信可以使用参数服务器完成，但是参数服务器和其他 NPU 工作时间是错开的，没有高效利用 NPU 的资源，且在通信过程中参数服务器带宽压力过大也会导致瓶颈。在之前的工作中引入了在网计算这一项技术，缓解了参数服务器带宽压力过大的问题，但是网络中可能并不能满足所有参数服务器全部被取缔，因此仍会存在参数服务器，并不能完全解决上面的问题。而另一种通信算法 Ring-Allreduce可以解决上面的问题，通过回环同步不同 NPU 之间的梯度。

流水线并行是将训练过程分成若干个层，每一层可以分开训练上一层的输出可以作为下一层的输入，这样可以大幅降低节点内模型大小，防止模型爆掉节点的内存。然而，这样会导致 NPU 利用率极低，因此微软提出了 Gpipe 方案，即将数据集也分成若干子集，每个子集独立通过流水线完成训练过程，此时网络中 NPU 利用率大幅提高，且随着子集粒度的降低，网络中 NPU 利用率也会随之降低。

![朴素流水线并行和Gpipe](https://img-blog.csdnimg.cn/img_convert/15c54d10e976d35c96e57965145300e8.png)

张量并行是指将训练过程中常用的矩阵乘法进行行并行或是列并行，分别在不同节点计算后通过加和或是拼接的并行方案。这类并行方案可以切分很大的模型，但是通讯量大，通信一般只在节点内部做多卡通信，不会做跨节点通信。

总结：

- **数据并行**：将数据集分割成多个子集，在多个设备上分别处理这些子集。这种方式能显著提高数据处理速度，但需要确保子集之间处理结果一致。
- **流水线并行**：将模型按层分割成若干块，每块都交给一个设备进行处理。这种方式能提高设备的利用率，但需要确保流水线中各阶段正确传递中间结果。
- **张量并行**：将模型的不同部分分配给不同的设备进行处理。这种方式能充分利用各种设备的计算能力，但需要注意设备之间的通信开销。

三种并行方案的通信量为：张量并行 > 数据并行 > 流水线并行

![image-20240619210947461](C:\Users\tbj20\AppData\Roaming\Typora\typora-user-images\image-20240619210947461.png)

上图是一个三维混合并行方案。数据集首先被分成两个子集，分别使用上下两层 NPU 训练；在每层 NPU 中使用流水线并行分别进行训练，这里模型被分成 4 层，每层使用一列 NPU 处理；在每一层流水线中，一列 4 个 NPU 使用张量并行训练这一层模型。可以看出，混合模型融合了不同并行方案的优势，每个 NPU 需要训练的数据集大小和模型大小被大幅降低了。在训练大模型时使用混合并行方案，不同 NPU 间的通信情况不同，这也对合理的网络调度提出了要求。

## 问题提出：

在混合并行场景下，使用光网络加速AI大模型训练任务，利用AI流量通信需求具有时序性，可预测性强的特点，规划 NPU 使用、流量调度和光互连拓扑的重构。

## 优化思路：

具体来说，若数据并行度为 N，训练集大小为 D，光网络中 Pod 数目为 P。将这些 Pod分成 N 份作数据并行，每一份训练 mini-batch 数据集大小为 $\dfrac{D}{N}$，并训练完整的模型参数。在每一组数据并行的 Pod 中将 NPU 再分成 M 组以进行层数为 M 的流水线并行。将 mini-batch 再细分成 micro-batch，使用 Gpipe 方案进行以提高 NPU 利用率。流水线的每一层都由一个 server 完成，一个 server 内有 T 张 NPU，可以进行并行度为 T 的张量并行。此时为了训练这个模型，我们使用了 $N*M*T$ 张 NPU。

训练过程：

1. 将数据集分成 N 个 mini-batch，分给不同的数据并行单元；
2. 将每个 mini-batch 再分成 M 个 micro-batch，并进行数据流水线并行；
3. 在数据进入每层流水线后，server 内的 NPU 间使用张量并行。而张量并行的通信和计算都是在 server 内进行，server 内 NPU 间有着高容量的卡间带宽，可以满足张量并行的高通信量要求，具体张量并行的过程与调度无关；
4. 每次张量并行求得每一层流水线的结果后，需要在各层流水线间进行通信以进行前后向传输，在完成反向传播后，梯度汇总并进行参数更新，这个传输过程可能是跨 Pod 的，因为一个数据并行单元可能包含多个 Pod，因此需要使用光交换资源和 Pod 内带宽资源。
5. 在完成后向传输后，完成一次流水线操作，获得了 mini-batch 训练更新的参数，还需要通过 ring-Allreduce 更新数据并行单元的参数，此时也需要使用光交换资源

可以看到，整个过程使用了两次光网络资源，需要进行拓扑重配以最大化提供的带宽。

可以发现，在流水线并行完成反向传播后并不是马上去做数据并行的的通信，而是要等待梯度汇总和参数更新，在这段时间里，网络是闲着的，就可以把这段时间用来将拓扑从流水线转成数据并行；在模型训练过程中，第一个 micro-batch 的训练时，网络也是空着的，可以将拓扑再从数据并行转到流水线，以进行后续的流水线操作。

此时，训练过程中网络空闲的时间就被用于拓扑重构，隐藏了拓扑重构的时间，最大化地利用了光网络拓扑变化灵活，吞吐量大的优势。

对于网络而言，我们希望的是在未知混合并行方式和并行度，未知训练数据量和各卡训练通信时间，且无需改变现有训练方案的情况下，同时，网络也无法截取流量中的包，只通过网络中可获得的数据，来预测网络中的流量和连接拓扑。

由于 AI 流量的时序性，每隔一段时间，流量需求便会循环一次，直到完成训练，可以依据这一特点，来预测同步训练下每一次所有卡完成训练后的流量需求，并在训练过程中改变光连接，从而使得在 NPU 训练过程中，光网络并不是赋闲的，而是在利用这段时间改变拓扑重构，在利用光网络高吞吐量和灵活性的同时，规避重构时间长的风险。问题不在这个基本思路里，这种重叠时间的思路在很多地方已经用到了，不具有新颖性。

主要问题在于预测。因为网络是不知道整个模型什么时候完成了一次混合迭代，因此不好预测混合并行的周期数，而且至少网络在第一个迭代是完全不知道循环是怎样的，因此会产极高的延迟。因此我们需要一个合理的方案快速获得模型一次迭代的拓扑队列，且由于大模型的规模，模型收敛需要的迭代次数极高，因此后续完全匹配的拓扑队列对模型训练的增益将完全覆盖前几次迭代的损失。

但是，网络的效率仍然没有被完全发掘，因为我们只是在训练过程中使得网络没有停止工作，但是通信过程中，NPU 仍然在摸鱼。。。要解决这个问题，应该在训练方面下手，与光通信的调度无关。

说回算法，如前所述，我们要预测的其实是循环的一个周期，即最小周期预测。方案如下：

1. 初始化：拓扑队列为空，循环次数为0；
2. 在训练过程中执行如下操作：

​        a. 若循环次数为0，拓扑队列为空，说明这是第一次循环的第一次通信，在训练过程置空所有光连接拓扑，在获得通信需求后计算拓扑连接方案，并将该拓扑放入拓扑队列，并将循环次数置0；

​        b. 若循环次数为0，拓扑队列不为空，说明这是第一次循环的非首次通信，不修改上次的拓扑，在获得通信需求后计算拓扑连接方案，判断连接方案是否与队列首个元素相同。如果相同，判定为出现循环，标记循环次数为1。反之，如果不相同，判定为在循环内，将该拓扑放进拓扑队列，并将循环次数置0；

​        c. 若循环次数大于0，说明已经获得了拓扑队列，此时取拓扑队列首个元素，按此拓扑在训练过程修改光连接。获得通信需求，计算拓扑连接方案，并与取得的方案做匹配。若相同，则直接开始进行光通信，若遍历完一次拓扑队列，将循环次数加1，并进入下一次循环；若不相同，说明此时获得的周期并不是最小预测周期，而是这个周期中的一部分，此时，需要重构拓扑队列，并将循环次数置0。

​        重构队列的具体方案为：将原拓扑队列复制循环次数次，再加上此次循环已经遍历的部分，就是新的拓扑队列。

​        d. 训练收敛时，结束算法

LLM 的流量特征：

LLM 的训练会在每台主机上产生少量周期性爆发流量，如400 Gbps 网络容量会被瞬间满足，持续时间几秒到几十秒不等，梯度同步导致了此类流量的产生。这会导致等价多路径哈希极化（多层哈希后流量不均），造成不确定流量分布的问题。且训练产生的通信连接需求往往只有数十到数百条，远远低于云计算。

LLM 的训练会要求GPU同步迭代，此时会对单点故障更加敏感。

GPU 规模：每个主机 8 个 GPU，每个数据中心 1875 个主机，共 15000 个 GPU，网卡吞吐量约 400 Gbps

传统数据中心和 LLM 匹配度不高。这是因为传统数据中心使用 ECMP 方式作为负载平衡方案。ECMP 假定当网络中存在大量流量时，哈希算法可以有效地将所有流量平均分配到所有等效路径上。这一假设在云计算流量模式下成立，因为云计算流量模式一般会产生数百万流量，不易出现极化。但是 LLM 流量数目低，数据量大，即大象流，容易产生哈希极化，严重影响效率。甚至，经典三层 clos 架构（ToR、Aggregation、Core）会使用三次哈希，因为每个流量哈希的五元组保持相同，这种级联哈希的效果会导致更严重的哈希极化。

当前的只是将预测和重叠时间两个比较老套的方案结合在了一个新的场景而已。

算法可已知模型并行方案和并行度，数据量等信息，可加入动态场景的调度，此时循环会发生变化，可以尝试为多个LLM业务做调度。其次，还可以联合调度混合并行方案和集合通信方案，并与INC结合。比如一个数据中心可以动态地为多个LLM提供服务，此外，联合调度混合并行方案和集合通信方案和INC使用方案。

## 拓扑选择：直接连接 or 间接连接？

直接通信：速度快，延迟低，扩展性差

间接通信：速度相对慢，延迟高，扩展性和灵活性高

混合通信：服务器内搭载多张 GPU，GPU 间采用 NVL、PCLe、QPI 高速互联，由于 RDMA 等技术的使用，服务器内 GPU 间通信带宽高，延时低。但是服务器内 GPU 的通信复杂度阻碍了服务器内 GPU 数目的增长，此时在服务器间采用间接连接以提高网络的可扩展性，服务器间连接可以采用 clos 结构组成三层 Fat-tree （？）。服务器间的通信引入光网络，利用其带宽高，可以适应倾斜流量的特性，来加速训练过程中倾斜的集合通信流量。

## 混合并行方案的选择：

DP+PP+TP

模型并行是三种并行方式开销最大的，因此将其放在服务器中，使用服务器内的高速互联来处理。在模型并行中会产生 AllReduce 流量，这部分流量会通过 NVL 快速传输，无需调度，模型并行度由服务器内 GPU 数目等因素决定。

数据并行通信开销高于流水线并行，尽量使用光网络，发挥其倾斜性和高带宽的优势，因此第一层并行采用数据并行，具体的集合通信方案的选择按下不表。

流水线并行通信开销最低，只在有必要时使用光交换。

若已知训练数据量、参数量和并行度，可以估算各处训练时间和集合通信时间，可以以此作为调度的前置信息。

## 集合通信算法的选取：

张量并行要进行数据同步，在服务器内采用 AllReduce 操作；流水线并行只有 send-recv 流量，传输的是上一层流水线的输出数据，无需集合通信算法；数据并行传输的是每个数据并行组的参数，其中的集合通信算法待选取，最经典的两种算法如下：

parameter server：参数服务器存在带宽瓶颈，在参数服务器和其他训练节点工作时间不重叠。但是可以通过部署 INC 来解决这一问题，此时网络设备就可以作为参数服务器，不会出现上面的情况。

ring-AllReduce：同样可以解决传统 parameter server 架构的问题，但是由于没有聚合操作，无法使用 INC，且随着 ring 的增大，集合通信效率会大大降低。

上面所说的数据并行->流水线并行->张量并行方案是针对数据量而言的，但是当考虑了集合通信算法后，混合并行方案也许会有不同。

若采用 parameter server 算法，数据并行组需要尽量处于同一个 pod 下，从而避免跨机架聚合，且能大幅降低 oxc 中的流量，因此混合并行方案可以为：流水线并行->数据并行->张量并行。（不一定就要用这种并行方式，因为此时 ToR 上的流量就是整个模型的数据量，网络瓶颈就在 ToR 上行带宽，会拉低通信效率，所以这部分还需要权衡）；

若采用 ring-AllReduce 算法，此时因为数据并行通信数据量更大，混合并行量可以为：数据并行->流水线并行->张量并行

## 多 LLM 业务在 server 使用、集合通信方案和集合通信上的共同调度：

数据中心网络中可能存在多个 LLM 业务，其出现也可能是动态的。怎样选取这些业务的并行方案和集合通信方案，怎样调度这些业务的集合通信流量？

以通信方案为例，在 INC 资源足够时，采用 parameter server 架构显然更好，但是如果 INC 资源被其他业务使用了，采用 AllReduce 可能就是更好的方案。

集合通信可以通过之前估算的训练和通信时间调度，通过预测流量周期以在训练过程完成光网络重构。

### 集合通信算法：

#### Ps-worker:可用于数据并行

确定拓扑方便（只需确定数据并行单元部署位置即可），使用限制多（单 pod、ToR 上的 INC 资源），完全无需使用 OXC。

#### AllReduce 类：可用于数据并行

难以确定拓扑，不仅需要确定每个数据并行单元的位置，还需要确定这些数据并行单元怎样互联成环/树。

##### 环算法：ring-AllReduce

单节点接受发送数据量达到最小，输入输出带宽用满，但是如果不只考虑带宽，再考虑每次传输的延迟

使用线性通信开销模型,$T = \alpha+S/B$

$T = （N - 1）(2\alpha + 2\dfrac{S}{NB}+\dfrac{SC}{N})$

其中， $\alpha$为设备间的通信固有延时，S为数据块大小，N 为节点数目，B为节点带宽，C为每字节计算耗时。

当 S 极大时，固有延时 $\alpha$ 可以忽略，此时随着N 的增大，延时 T 与 N 无关，为$T = 2\dfrac{S}{B}+SC$。

但是当 S 特别小，或者 N 特别大时，后两项就被忽略了，此时 $T = 2(N-1)\alpha$，此时延时由固有延时决定，随着 N 的增大持续增加。这就是环算法的缺陷，正因如此，树算法才被开发出来。

##### 树算法：tree-AllReduce

树算法实际在英伟达 NCCL 投入使用的方案是双二叉树法，使用两个对称二叉树解决传统单二叉树算法节点输入输出带宽量不同的问题。

根据论文，其延迟为$T \leq 4\alpha\log N+\dfrac{2S}{B}+2\sqrt{8\log N\alpha\dfrac{S}{B}}+(\sqrt{2\log N\alpha S}+S)C$

可以看出树算法对 N 极大的情况表现比环算法好得多。

但是树算法在同样的节点数目情况下，需要建立的连接数比环算法多得多，拓扑的复杂度更高。

#### 分层 ring-AllReduce

即将环分为两层，可以缓解 N 极大带来的延迟提高。连接数多于普通环算法，但是总时间在 N 较大时更低。但是如果 N 非常大，树算法的表现更好。

#### AlltoAll: 只用于 MoE 并行

1. 为已知混合并行需求的业务提供服务；

2. 假设分别使用不同的集合通信算法，分别寻找合理的 GPU 部署方案和拓扑，选择最优的部署方案和通信算法

部署方案的优异程度怎样确定？

1. MLU

2. 集合通信是否需要重构 OXC，重构次数多少？

3. 在多业务情况下，不同时间集合通信复杂度不同，可能在某时刻只有一个业务需要通信，可能某时刻有多个业务同时有集合通信需求，如何联合考虑所有情况下通信时间的优劣？

背景：传统的数据中心网络在训练大模型时，会由于哈希极化现象，导致网络中的流量不均衡，从而造成网络瓶颈。而光互连由于可以通过灵活变更拓扑，使得网络可以适应倾斜流量，在理论上，表现会远远优于传统的数据中心网络。但是由于技术原因， oxc 的端口数目在大规模场景下难以支撑其实现全部 pod 间的互联，为了缓解这种情况，我们引入了 INC 技术来降低网络中的流量大小，使得有限的端口数目能够应对更多的流量场景，同时还可以通过联合优化并行策略和通信算法，进一步缓解这一问题。

1. 并行策略级：混合并行的策略已经有研究了，在 SmartMoE、Alpa等文章中已经讨论过多种混合并行方案怎样选择，和专家并行时 expert 如何部署的问题。在这一部分可以尝试再将 INC 引入考虑场景，进一步优化在有 INC 场景下的选择；

2. 通信算法级： PP 流量比较简单，无需特定的通信算法，TP 常常被放在服务器内部使用 NVLink 高效互联，不会占用网络的带宽，因此不在我们考虑范围内。问题主要集中在 EP 和 DP 两种并行方案上，其中 EP 每次迭代都会在 expert 间出现两次不均匀的 AllToAll 通信，这部分通信在 DeepspeedMoE 中已经做了优化，目前针对 EP 中的集合通信优化除此之外几乎没有其他的方案；DP 需要做 AllReduce ，存在多种已成熟的方案可供选择，当下主流的算法为 ring-AllReduce，但在英伟达的集合通信库中，使用的是 tree-AllReduce，在特定的场景中，也有不同的 AllReduce 算法被开发，如果将 INC 及其限制引入考虑场景，那么参数服务器也可以是一种待选择甚至更加优秀的方案，而网络中大概率不是只跑一个业务，对不同的业务来说，可能更适合采用不同的算法，算法的选取不仅和业务本身有关，还与并行策略中怎样部署相关的并行单元有关；

3. 流量调度级：确定 OXC 的连接方案，使得在网络拓扑不发生变动的情况下，逐个处理业务通信需求，从而使得网络的训练效率更高。如果网络拓扑不能满足每一个业务的通信需求，则在每一次迭代的过程中，网络都需要重构，而每次迭代网络重构延时数百毫秒，在动辄千万次迭代的大模型场景里是不可容忍的。这一部分如果要考虑的很细的话非常复杂，虽然网络中同一个业务的流量是周期性的，但是多个业务放到一起，情况就会变得非常复杂且不易调度，难以使用周期性质，因此这一部分目前看先按照最简单的方案，就是通信需求分开，不同的业务不能同时使用网络资源。

#### 

#### 问题描述：

在在线模式下，数据中心网络会随时出现分布式的混合并行训练业务，每个训练业务存在若干次迭代。已知每个业务各并行方式的并行度，怎样将业务的各并行单元分配给网络中各 pod 上的 GPU 才更合理？在确定业务部署方案后，每个业务在每次迭代的通信过程应当采用怎样的聚合策略和路由策略？每个业务分配的带宽量又是多少？

#### 问题输入：

1. 网络特征及各项参数：三层 clos 脊叶网络，ToR 与 server pool 间的带宽，oxc 连接数目，单 OXC 连接带宽量，每个 ToR 下的 server pool 资源池，ToR 数目，单 ToR oxc 端口数目，单个 worker 上搭载的 GPU 数目；

2. 业务特征：每个业务的并行方案和各层并行度，业务每次迭代的训练用时，业务通信量和通信类型；

3. 交换机聚合器资源；

#### 假设：

1. oxc的传输方案选择全双工，也就是说一条连接可以同时为两个方向的流量提供相同大小的带宽；

2. 当前只考虑单跳转发，不考虑两跳及以上；

3. 由于张量并行一般在服务器内部进行，不会使用到外部带宽，因此混合并行中不考虑张量并行；

4. 不同并行方式下各并行单元间的通信模式：EP：AllToAll；PP：Send-Recv；DP：AllReduce，混合并行下三种流量都会存在；

5. EP 并行的 AllToAll 通信由于 Gate 概率问题不会是均匀的，为了简化考虑，认为该过程为单纯的数据块转置操作，此时每对并行单元间都会出现通信需求；

6. DP 并行的 AllReduce 通信可以使用在网聚合，但是并不是每次通信，在网聚合的资源都是空闲的，因此网络不仅要有在网聚合的能力，在没有在网聚合是也能通过相应的 Reduce 算法来解决。具体实现时在打包数据的时候把是否使用在网聚合放进 head 段用来识别聚合方案就可以了，配合路由方案选择的算法按理来说可以实现不同迭代使用不同聚合方案的操作;

7. 假设网络中所有 ToR 都可以使用在网聚合；

8. 在网聚合可以使用 ring 拓扑，这比使用 PS 结构更加合理。相对于 PS 结构来说，ring 拓扑不会在任何地方产生带宽瓶颈和聚合器资源瓶颈，也无需使用二级聚合。

9. 在网聚合需要使用聚合器资源，会使用 ToR 上的带宽资源，假设网络中的聚合器资源不能完全满足所有任务的通信需求，此时我们不得不使用 AllReduce 算法。按理来说，每个业务使用的聚合器资源应该和带宽分配匹配，防止因为计算速度过慢导致拖带宽的后腿；

10. PP 的流量是在训练过程产生的，使用 GPipe 操作后，每层间的前向传播时间不是错开的，而是通过 microbatch 进行了流水化，传输的是每层输出的结果；DP 的流量是各数据并行单元训练完毕后进行的，传输的是模型梯度；EP 的流量是 token ，在专家并行单元间会进行一来一回两次传输，第一次传输是训练完成后还回 token，第二次传输是训练开始前交换 token。

11. 在混合并行过程中，第一层为数据并行，即将数据集分成多份，并将复制同样数目的专家单元，将这些数据集输入各自的专家单元；然后每个专家单元由若干 moe 层组成，这些 moe 层间存在通信；在 moe 层中有若干 expert ，每个 GPU 上可能有多个 expert，这些 GPU 间存在 AllToAll 通信。其中，流水并行和专家并行都是和训练计算过程深度交叉，可以算作训练的一部分，且相对于数据并行，它们的通信量不高；

12. 当同一个 ToR 上存在多个 DP 单元时，ToR 和 server pool 之间三种并行的流量并存，DP 并行产生的 AllReduce 流量远大于其他两类流量，EP 和 PP 流量相对较小，且流量相对 DP 不好预测，EP 更是会出现流量不均的情况。此时由于流量大小的原因，其需求的带宽大小也是 DP 更大，此时假设只考虑 DP 流量，另外两种流量带宽分配不大，相对 DP 可以忽略不计。但是一旦出现一个 DP 单元被放在两个不同 ToR 下，此时不得不为其分配一条连接以保证训练时的传输需求，此时如果这条连接上存在 DP 流量，则考虑传输时间时只考虑 DP 流量传完的时间，反之，则这条连接上流量的传输时间不参与考虑。

#### 待解决的问题：

1. 部署问题：初始业务 GPU 部署问题，将 GPU 部署进网络后怎样部署各并行单元；

2. 流调度问题：为每个业务的通信计算两种 AllReduce 方案，分别是使用在网聚合和不使用在网聚合；在在线模式预测业务的通信需求，并为其确定通信方案，若使用在网聚合，确定使用的聚合器资源及资源位置，若不使用，则确定网络拓扑和带宽分配，确定是否使用 oxc 重构。在通信过程中，不同迭代下的通信方案可以不同，用以适应不同场景；

3. 拓扑重构什么时候做？怎么做？怎么算新拓扑？

#### 优化目标：

GPU 平均训练时长，由于未知迭代次数，无法计算平均完成时长，因此摒弃使用平均化时间的思路，转而提高 GPU 利用率。

##### 调度方案

避免使用 time-slot 的方法，而是在每个通信需求开始和结束时都做一次带宽分配优化。

定时检查更换拓扑，以适应不同通信需求，或是新业务加入和业务完成

##### 业务并行单元部署方案：（这里存在两种不同的部署方案，一种 DP 通信使用 oxc，一种 PP 通信使用 oxc；还有要增加复用拓扑的考虑）

###### 部署方案希望满足的要求：

1. 由于每个 ToR 的带宽量相同，因此且由于聚合的性质，每个 ToR 输入输出的流量大小其实是一样的，因此各 ToR 的输出流量需要相近，否则在有的 ToR 时刻输出的时候，有的 ToR 大量空闲，这是不合理的，因此优化目标1为：每个 ToR 的输出总数据量度量近似，即$\min\{\text{总数据量度量方差}\}$，这里的度量不仅要考虑单次迭代的数据量，也要考虑传输需求出现的频率。我们认为训练时间和传输时间成正比，因此每个业务的数据量度量=业务每次迭代数据量/训练时间；

2. 每个 ToR 的连接数目要尽可能少，最低的要求是连接数不能超过端口数目，这是因为传输要求在实际训练过程中并非是并发的，可能有时间差距，或者不完全重叠等情况。我们希望减少业务间共用源 ToR 但不共用目的 ToR，或是共用目的 ToR 但不公用源 ToR 的情况，因为这种情况会导致大量是否重构的复杂取舍，即重构后该业务可能可以使用更多连接，极大加快传输效率，但是重构时长高，此时需要做出取舍，而且出现这种情况时，两种方案都有较大缺点。为了减少这种可能，提高两种方案的平均效率，设优化目标2为：在全部使用 ring + inc 的情况下，$\min\{\sum各 ToR连接其他 ToR 数目\}$。

先确保平均流量，再保证最小连接需求数。具体的方法为先以平均化方式为主部署一部分流量，然后换用以减少连接需求数为主部署剩下的业务。然后可以再对部署方案进行微调，以能接受的代价，继续减少每个 ToR 的连接需求数目。但是初始连接在部署是还不好确定，需要再重新选择优化目标。具体的初始拓扑会按照流量度量值降序为业务算 ToR 连接，我们也按业务度量值来计算理论重叠度。

##### 业务并行单元部署与业务拓扑计算：

1. 计算每个业务的流量度量值，降序排列之，并按某比例将队列分成两个部分，第一部分的流量度量值比第二部分大，逐个对业务进行如下处理：

2. 对第一部分业务，逐个部署 DP 单元，每个 DP 单元都部署在剩余 server pool 资源最多的 ToR 。第一个业务的部署无需考虑复用源/目的 ToR ，逐个部署 DP 单元至 ToR 上，如果无法部署，则对 DP 单元进行拆分，拆开后不同的部分分别放到剩余资源最多的 ToR，按索引顺序成环，拆分的 DP 单元间也需要一条连接，记录所有连接的源/目的 ToR 对；后续的业务 DP 单元部署方案不变，但是成环方式不同，找到所有该业务相关的复用 ToR ，搜索满足源/目的 ToR 对的所有连接，构成一个拓扑。但是这个拓扑有可能形成子环，此时需要对其进行解子环：首先要找到所有子环，按索引序遍历 2 节点度节点，根据节点当前连接找到下一个节点，直到找到一个 1 节点度节点，这就说明，这些找到的节点都不可能形成子环，按此方式排除所有节点，即可找到所有子环拓扑。如果存在子环，找到子环中合适的连接并删除之，即可完成解子环操作。适合删除的连接为：遍历子环中的连接，找到总流量最小的连接，子环从这个连接解开即可。计算这个拓扑各节点的节点度，如果节点度大于 2，说明要删连接。按节点度降序排列所有节点，并按序遍历处理之：首先判断节点度是否大于 2，如果不是，直接结束删除；反之，检查该节点连接的其他所有节点，找到这些节点中节点度最大的，删除这两个节点之间的连接。然后找出该业务节点度小于 2 的节点，即 0 节点和 1 节点。为了避免过早成环导致最终拓扑会形成多个环，首先处理完所有的 0 节点，让其至少变成 1 节点：找到所有 0 节点，找到最小索引，连接下一个 0 节点，然后删掉这两个已连接节点后重复这个过程，最后最多会剩下一个 0 节点。然后剩下的 0 节点找到最低索引的 1 节点连接，然后 0 节点就不存在了，再将 1 节点进行两两互联，此时最终的拓扑就变成了一个 ring；

3. 对第二部分业务，同样逐个部署 DP 单元，但是部署时不按剩余 server pool 资源部署，而是按照连接情况部署，在拓扑中找出所有环是困难的，此时因为第一部分业务造了若干个环，可以存储其拓扑，找到环大小小于等于 DP 单元数目的环拓扑。找到所有可用环拓扑，然后计算分别部署后 ToR 各输出流量方差，取最小者如果找不到可用拓扑，问题此时转化为第一部分；

4. 输出部署方案，和各业务的环拓扑连接方式；

##### 初始拓扑求解：

目的：为第一个重构时间的通信任务预留连接，INC 和非 INC 流量分开，便于调度。OXC 按照全双工方式工作，ring 的时候分两个方向做 ring 即可完全利用正反两方向带宽。

1. 根据环拓扑计算每个业务的跨 pod 流量度量值矩阵，将一个重构时间内所有业务的流量度量值矩阵累加得到当前总流量度量值矩阵，因为上面所说的双向 ring 的方案，这些流量度量值矩阵必定是对称矩阵；

2. 检查每行的非零单元数，如果大于单 pod 能提供的连接数，此时说明连接数不够，需要预留公共 ring 拓扑。检查每个 ToR 上各方向的流量度量值大小，除连接了同一个 DP 单元不同部分的 OXC 外，如果存在某方向的流量占比低于一个设定好的阈值，说明这部分就是分不到连接的，此时也需要预留公共拓扑；如果上面两个条件都不满足，那就说明连接资源够用了。但是还需要评估聚合器资源，每个交换机调度的流量有两部分，分别是本地模型的梯度，和通过 ring 结构传来的梯度，本地可能部署了多个模型，而通过 ring 结构进入交换机的流量也有两个方向，分别传输了半个模型大小的数据量，合计也是一个模型量的数据。如果聚合器可以聚合的带宽量大于 ToR 与 server pool 间的带宽 + OXC 输入 ToR 的总带宽，这说明聚合器的聚合能力相对溢出了，此时完全无需考虑聚合能力不足的问题，问题也变成了单纯的连接和带宽分配。反之，说明聚合器的聚合能力并没有溢出，而是会出现不够的情况，此时仍然需要考虑聚合器资源；

3. 如果要预留连接，则将 ToR 按索引序连接，每对 ToR 只保留一根连接。这根连接专门用以做不使用聚合的集合通信过程，不和使用聚合的通信过程共用，但可以复用 DP 单元内部的 PP,EP 流量。然后将总流量度量值矩阵中低于阈值的元素置为 0 ，然后做近似算法分剩余的连接，具体的方法是按各方向流量比例，乘剩余连接数，并对结果四舍五入，如果这些结果相加大于连接数，那多分配的连接从流量/连接最小的方向删起，直到等于连接数；反之，如果相加小于连接数，那就为流量/连接最大的方向增加一条连接，直到等于连接数；

4. 输出拓扑连接矩阵。

##### 拓扑和带宽调度方案：

在每个重构时间内的调度不使用更细的时隙，而是通信开始或完成都会直接让算法知道，中心控制器可以以极小的时隙检测各业务是否完成传输并作出反应，然后马上计算修改带宽分配。具体的带宽分配策略为先到先服务，即先满足早到的通信需求，然后再满足后到的，如果有业务完成，腾出的带宽也是按此顺序分配，直到用满所有带宽。

拓扑可以使用在网聚合就使用在网聚合，即使这可能需要等待资源空闲。使用预约资源的方案，用一个预约队列来存放这些业务。在网聚合流量不考虑多跳转发，但是非在网聚合流量考虑，因为要用一个拓扑满足所有要求，多跳转发是必须的。

由于带宽，流量大小都是对算法可见的，因此可以预测到每个重构时间内网络的所有动作，并能预测到下个重构时间的流量情况。但是这样做繁琐且存在漏洞，不能很好的预测到下一个重构时间的流量。这是因为下个重构时间内的流量就需要知道本次重构的带宽分配，就算是本次重构的带宽分配已经确定，可以知道每个业务在本次重构后什么时候有下一次通信需求，如果一次重构时间该业务会出现多次通信，也无法很好地获得下次重构的通信需求。因此只能近似地预测通信需求会在何时出现，在一个重构时间会出现多少次。使用每个业务 N 次迭代的数据预测每个业务后续的迭代时间。

引入预约资源制，防止后续的业务先用这些业务导致冲突。

1. 第一个重构时间：初始拓扑使用上个算法求解。然后使用先到先服务方式分配带宽，因为不知道业务迭代次数，平均化时间的想法是不合理的，先到先服务更简洁合理。即先到达的业务先开始服务，如果网络中通信任务完成，先到达的业务更早享用腾出的带宽资源。记录业务完成部署的时间，部署完成的业务放进未完成业务集合 $J$，以供后续遍历。建立通信中队列 $P$，当网络中出现通信需求时，将该业务放在队列末，当网络中通信需求被完成后，完成的业务会被移出队列。

2. 进行第一个拓扑重构时间内的调度：在业务通信需求产生时，将业务放进队列 P 中，然后对该业务进行决策，判断其是否使用在网聚合，然后

3. 预测下一个重构时间内的流量，找到拓扑中可以删除的（不可删除的：现有业务 ring 的预留连接，moe 层间连接）待传输和预约传输流量少的连接，如果断开的连接上有流量，让这个流量相关的任务先完成，然后断开并重构这一部分连接，将这些流量相关的后续业务强制改为使用 ring 方案，以适配下一个重构时间的流量；

4. 在完成第一个拓扑重构时间内开始的所有业务后，此时完成了第一次拓扑重构，检查是否有业务完成或出现，预测流量，找出下一个拓扑重构时间内可以删除的连接，强制改变业务聚合方案，删除连接，开始重构；

5. 循环按上述过程。

##### 业务开始传输的选择和调度方案：

1. 检查业务使用在网聚合需要的资源（带宽、聚合器）是否存在空闲（可能有多个聚合器和路由方案可以使用），使用 ring 的业务中途可以改变带宽，使用在网聚合的业务中途不改变带宽和聚合器数目分配，因为太麻烦。。。。

2. 如果不存在空闲，预测等待时间，即等待当前业务和所有预约业务完成聚合的时间$t_{wait}$，除此之外，还要看这个时间后，业务的瓶颈处什么时候有业务减少，完成业务后能腾出多少资源，记录；

3. 分别计算 ring 结构预测时间，ring 结构的带宽占用与业务数据量成比例，和使用在网聚合的时间，和等待后在网聚合的时间，找最小值，如果是 ring 最小，那就直接用 ring，反之，预约该聚合器的资源和带宽的资源的占用时段，从而确定二阶聚合的方案；

4. 根据二阶聚合的方案，如果二阶聚合采用 ring 结构，一阶聚合直接看是否有足够的资源即可，看瓶颈在什么时间后有业务减少，能腾出多少资源，分别计算在网聚合和 ring 的时间+等待时长，找到加上二阶聚合时间最低的方案；

5. 如果业务无法支持在网聚合，或是 ring 时间最小，那么按照传输总数据量大小比例分配带宽；

##### 冲突

1. 任务位于同一 ToR 下，无论是否使用在网聚合，带宽资源会出现瓶颈，需要多个 ToR 的带宽资源以缓解该问题；

2. 位于不同 ToR 下，OXC 端口资源会产生危险，且 INC 资源使用也会增加。最极端的情况是，所有 DP 并行单元位于不同的 pod 下，此时 oxc 资源使用和在有无 INC 都一样，两种方案此时差别不明显，不能很好的凸显 INC 的优势。如果使用在网聚合，瓶颈位于总通信量最大的交换机处，可以根据瓶颈处的带宽资源确定各 ToR 最大并行组数。或者说，各交换机聚合连接数需要尽可能匹配，避免出现带宽和聚合器瓶颈。

#### 不同并行方案的特点

1. EP 使用 AllToAll 通信，其通信并不均匀，也不可预测，而由于 EP 每次迭代计算时间都不一定长于重构延时，而固定的光拓扑又无法适应变化的流量，因此 EP 并行组应当尽量位于同一 ToR 下，以获得更加灵活的带宽分配；

2. DP 使用 AllReduce 通信。此时 DP 并行组会出现上面所说的冲突，需要妥善安置 DP 并行组的位置；

3. PP 流量少，连接资源消耗少，用的也少。。。；

4. TP 被放在服务器内部，使用 NVLink 互联解决其 AllReduce 流量大，通信繁琐的问题。

#### 部署方案：

##### Input

1. 业务队列；

2. 各业务参数：各并行度，考虑三种并行（EP/DP/PP），默认服务器内部使用 TP 不参与考虑，模型中最小的运算单元为 server，内部搭载 8 张用 NVLink 和 PCLe 互联的 GPU。采用三元组（e, d, p）表示并行度；业务使用 GPU 总数；业务训练总数据量和业务模型参数总量（据此计算单 GPU 训练数据量和模型大小，以估计单次训练时间与流量大小）；

3. 网络参数：pod 数目，单 pod server pool 大小，超额订阅比（1:1）

##### Output:

1. 业务部署方案

要求：减少后续调度复杂度。